{
  "runSettings": {
    "temperature": 1.0,
    "model": "models/gemini-3-pro-preview",
    "topP": 0.95,
    "topK": 64,
    "maxOutputTokens": 65536,
    "safetySettings": [{
      "category": "HARM_CATEGORY_HARASSMENT",
      "threshold": "OFF"
    }, {
      "category": "HARM_CATEGORY_HATE_SPEECH",
      "threshold": "OFF"
    }, {
      "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
      "threshold": "OFF"
    }, {
      "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
      "threshold": "OFF"
    }],
    "enableCodeExecution": false,
    "enableSearchAsATool": false,
    "enableBrowseAsATool": false,
    "enableAutoFunctionResponse": false,
    "thinkingBudget": -1,
    "outputResolution": "1K",
    "thinkingLevel": "THINKING_HIGH"
  },
  "systemInstruction": {
  },
  "chunkedPrompt": {
    "chunks": [{
      "driveDocument": {
        "id": "1CnZgM9E25DWMP0vK8D2tFUd17yPfCOOs"
      },
      "role": "user",
      "tokenCount": 26115
    }, {
      "driveDocument": {
        "id": "1fpll-un4EGF4EeVvVwlABtxNc9NRumGm"
      },
      "role": "user",
      "tokenCount": 74324
    }, {
      "text": "I\u0027m having trouble with speed between the harness (which is faster - achieved 1200 blocks per second with 10-20 peers), and node (modernized and full rewrite) - achieving 400 blocks/s with 20 peers in benchmark mode (which should copy harness).\n\nI\u0027m trying to understand where is the bottleneck, or maybe we\u0027re doing something wrong in the pipeline. Could you analize both repos and tell me where to look at? And if you can - make a comparison between their ingestion/networking flows/pipelines?",
      "role": "user",
      "tokenCount": 121
    }, {
      "text": "**Framing the Comparison**\n\nI\u0027m now zeroing in on the core of the problem: a direct comparison between the \"harness\" and the \"node\" codebases. I need to understand why the \"node\" codebase is significantly slower, aiming to identify specific areas ripe for optimization. This requires a granular view.\n\n\n**Diving into Harness Architecture**\n\nI\u0027ve been meticulously analyzing the harness codebase, particularly `repomix.harness.xml` and `main.rs`. Its monolithic structure is clear, and I\u0027m focused on how it manages state with the `RunContext` struct, wrapped in an `Arc` and protected by mutexes. The scheduling, which uses a `ready_rx` channel for peers and spawns a new Tokio task for each batch, has grabbed my attention.\n\n\n**Unpacking Node Scheduling**\n\nI\u0027m deep in the node\u0027s scheduling now, particularly `PeerWorkScheduler` and the loop in `run_benchmark_probe`. A `JoinSet` handles fetch tasks and I\u0027ve zeroed in on the `ready_rx` channel being fed by a `peer_feeder`. I\u0027m comparing this to the harness\u0027s scheduling. The crucial difference seems to be the re-queuing mechanism; the order may be a critical bottleneck.\n\n\n**Scrutinizing P2P Interactions**\n\nI\u0027m now zeroing in on the P2P layers of both systems. In the node, `NetworkSession` and `NetworkHandle` are key, alongside `PeerRequestSender`. I\u0027m comparing the fetching logic, particularly the `request_headers_chunked` flow, looking for nuances. I\u0027m especially interested in how the node\u0027s `PeerWorkScheduler` uses `Mutex` and how this contrasts with the harness\u0027s queuing and channel handling. My initial hypothesis centers around how P2P requests are managed and dispatched.\n\n\n**Comparing Request Chaining**\n\nMy focus is narrowing in on the differences in header and receipt fetching between the \"node\" and the \"harness.\" I\u0027ve discovered the \"node\" implementation uses chained requests within `request_headers_chunked` to retrieve headers, and also receipt retrieval. The harness does batched requests. The potential bottleneck lies in this serialized, chained request structure, which demands closer scrutiny as it contrasts with the harness\u0027s batched methods.\n\n\n**Evaluating Batch Processing**\n\nI\u0027ve examined the code snippets, focusing on receipt retrieval. Both systems fetch receipts sequentially within a batch, which eliminates a primary concern. The real differences are in how jobs are dispatched and processed.\n\n\n**Investigating Peer Re-use**\n\nI\u0027ve pinpointed a major difference in how peers are handled. In the node, `spawn_peer_feeder` aggressively pushes all peers to `ready_tx` every 200ms. Conversely, the harness feeds peers to `ready_tx` on demand. This could create significant contention and context switching in the node, impacting performance as the harness efficiently manages peers. Further investigation is required to determine the exact impact.\n\n\n**Analyzing Channel Bottlenecks**\n\nI\u0027m now zeroing in on a potential flaw in the node\u0027s peer handling. It appears `ready_tx` is spammed every 200ms with *all* peers by `spawn_peer_feeder`, even if they are already working. This raises serious concurrency concerns because `PeerWorkScheduler` might be pulling the same peer ID from the channel, leading to duplicated work. The harness\u0027s bounded `ready_rx` offers a stark contrast, which may reveal a key performance bottleneck.\n\n\n**Assessing \"In-Flight\" Logic**\n\nI\u0027m now zeroing in on a critical comparison of the \"in-flight\" request management. Specifically, I see how each peer handles requests. While the node uses a feeder to rapidly queue peers, the harness only re-queues them when their work is complete. The network layer, via `PeerRequestSender`, handles the pipeline requests. I\u0027m focusing on whether a flooded peer could lead to dropped requests.\n\n\n**Evaluating Network Congestion**\n\nI\u0027m now diving into the network-level details, especially peer management. I\u0027ve noted the node\u0027s `PeerRequestSender`, a handle to an mpsc channel, and suspect excessive parallel requests to the same peer could be problematic. I see a `peer_feeder` that aggressively re-queues peers, potentially leading to channel congestion if peers can\u0027t keep up. The question is, does this over-eager queuing cause bottlenecks? I am seeing how the network layer is configured.\n\n\n**Differentiating Peer Management**\n\nI\u0027m now comparing the \"node\" and \"harness\" peer management strategies. I see the node uses a `PeerPool` (RwLock\u003cVec\u003e), while the harness uses loose handles, passed through channels. The node\u0027s `peer_feeder` aggressively spams `ready_rx`, especially when the `PeerPool` is small, potentially creating contention. I need to determine the consequences of this `PeerPool` design in the context of network events.\n\n\n**Investigating Wait/Backoff Logic**\n\nI\u0027m now zeroing in on a significant difference in how the \"node\" and \"harness\" handle periods of inactivity. The node\u0027s `run_benchmark_probe` function employs a 50ms sleep and re-queuing loop when the scheduler is idle or work can\u0027t be found for the given peer. The harness, conversely, simply drops the peer from the `ready_rx` loop if no work is available at that time, and relies on `next_batch_for_peer` to re-integrate the peer. I\u0027m focusing on the effect of the node\u0027s busy-loop on overall performance and resource utilization.\n\n\n**Refining Peer Re-Integration**\n\nI\u0027m now focusing on peer re-integration in both systems. I\u0027ve realized the harness *does* drop peers from its main loop if there\u0027s no work, a potential inefficiency assuming the queue isn\u0027t always saturated, which is the assumption. The node, conversely, actively tries to keep peers alive, even when idle, which could cause overhead if its scheduler is constantly re-queuing empty tasks, which I am now confirming. My latest hypothesis is the node\u0027s P2P request implementation is the bottleneck, now taking a close look at `request_receipts_legacy` call.\n\n\n**Examining Request Splitting**\n\nI\u0027ve been analyzing the receipt retrieval mechanisms. The node\u0027s `request_receipts_chunked` function, with its logic for handling partial results, now has my attention. I\u0027m comparing it against the harness\u0027s more straightforward approach. While the node does some receipt mapping and re-assembly, I\u0027m not convinced it would significantly slow things down. My focus now is on what the node does in its implementation of the P2P connection, and it is likely where the time is being spent.\n\n\n\n**Comparing Pipeline Efficiency**\n\nI\u0027m now comparing the \"node\u0027s\" multi-stage pipeline with the \"harness\u0027s\" inline processing. The node\u0027s fetch-process-sink design, using multiple channels, is under scrutiny. I see a potential bottleneck in the multi-stage pipeline, and now I have more specific hypothesis on that area. I\u0027m focusing specifically on the impact of this channel-based design, and if the single-stage design is a factor.\n\n\n**Identifying Data Movement Costs**\n\nI\u0027m now focusing on the performance implications of data movement through channels in the node. Specifically, the transfer of large `Vec\u003cReceipt\u003e` instances via `fetched_blocks_tx` is a key concern. In comparison to the harness, where the data is moved directly into a closure, the node\u0027s multi-channel approach might incur significant overhead due to memory copying. I am also investigating whether the channels are a cause of contention.\n\n\n**Isolating Node Concurrency**\n\nThe node\u0027s excessive parallel requests to the same peer, due to its `peer_feeder`, are becoming clearer. The `PeerWorkScheduler` lacks \"peer busy\" tracking. Consequently, multiple concurrent `fetch_probe_batch` tasks might run for the same peer, which I see as the likely source of performance degradation. I\u0027m considering fixing this by modifying the `peer_feeder` loop.\n\n\n**Fixing Concurrency Issues**\n\nI\u0027m now zeroing in on a pair of potential fixes, which includes removing the redundant peer feeder, which floods the ready channel. Next, I\u0027m going to optimize the pipeline to avoid sending the full fetched blocks to the processor thread. Finally, both node and harness use BinaryHeap, and Mutexes.\n\n\n**Validating Queue Growth**\n\nI\u0027m confirming the \"infinite growth\" of queue items and concurrent overlapping requests to the same peer, as revealed by the code snippets. The `spawn_peer_feeder` aggressively pushes peers onto the `ready_tx` channel every 200ms, while `run_benchmark_probe` re-queues them. This 1-to-1 mapping explains the performance bottleneck. Now to focus on providing code fixes.\n\n\n**Addressing Peer Flooding**\n\nI\u0027m now zeroing in on actionable code changes. The `peer_feeder` is the primary culprit, causing excessive parallel requests and queue growth, and needs adjustment within `sync/historical/mod.rs`. I\u0027m also planning to evaluate if there is any benefit to reducing channel serialization. The differences in locking strategy, particularly how the node handles batch assignment versus the harness, requires closer consideration.\n\n\n",
      "role": "model",
      "tokenCount": 5521,
      "isThought": true,
      "parts": [{
        "text": "**Framing the Comparison**\n\nI\u0027m now zeroing in on the core of the problem: a direct comparison between the \"harness\" and the \"node\" codebases. I need to understand why the \"node\" codebase is significantly slower, aiming to identify specific areas ripe for optimization. This requires a granular view.\n\n\n",
        "thought": true
      }, {
        "text": "**Diving into Harness Architecture**\n\nI\u0027ve been meticulously analyzing the harness codebase, particularly `repomix.harness.xml` and `main.rs`. Its monolithic structure is clear, and I\u0027m focused on how it manages state with the `RunContext` struct, wrapped in an `Arc` and protected by mutexes. The scheduling, which uses a `ready_rx` channel for peers and spawns a new Tokio task for each batch, has grabbed my attention.\n\n\n",
        "thought": true
      }, {
        "text": "**Unpacking Node Scheduling**\n\nI\u0027m deep in the node\u0027s scheduling now, particularly `PeerWorkScheduler` and the loop in `run_benchmark_probe`. A `JoinSet` handles fetch tasks and I\u0027ve zeroed in on the `ready_rx` channel being fed by a `peer_feeder`. I\u0027m comparing this to the harness\u0027s scheduling. The crucial difference seems to be the re-queuing mechanism; the order may be a critical bottleneck.\n\n\n",
        "thought": true
      }, {
        "text": "**Scrutinizing P2P Interactions**\n\nI\u0027m now zeroing in on the P2P layers of both systems. In the node, `NetworkSession` and `NetworkHandle` are key, alongside `PeerRequestSender`. I\u0027m comparing the fetching logic, particularly the `request_headers_chunked` flow, looking for nuances. I\u0027m especially interested in how the node\u0027s `PeerWorkScheduler` uses `Mutex` and how this contrasts with the harness\u0027s queuing and channel handling. My initial hypothesis centers around how P2P requests are managed and dispatched.\n\n\n",
        "thought": true
      }, {
        "text": "**Comparing Request Chaining**\n\nMy focus is narrowing in on the differences in header and receipt fetching between the \"node\" and the \"harness.\" I\u0027ve discovered the \"node\" implementation uses chained requests within `request_headers_chunked` to retrieve headers, and also receipt retrieval. The harness does batched requests. The potential bottleneck lies in this serialized, chained request structure, which demands closer scrutiny as it contrasts with the harness\u0027s batched methods.\n\n\n",
        "thought": true
      }, {
        "text": "**Evaluating Batch Processing**\n\nI\u0027ve examined the code snippets, focusing on receipt retrieval. Both systems fetch receipts sequentially within a batch, which eliminates a primary concern. The real differences are in how jobs are dispatched and processed.\n\n\n",
        "thought": true
      }, {
        "text": "**Investigating Peer Re-use**\n\nI\u0027ve pinpointed a major difference in how peers are handled. In the node, `spawn_peer_feeder` aggressively pushes all peers to `ready_tx` every 200ms. Conversely, the harness feeds peers to `ready_tx` on demand. This could create significant contention and context switching in the node, impacting performance as the harness efficiently manages peers. Further investigation is required to determine the exact impact.\n\n\n",
        "thought": true
      }, {
        "text": "**Analyzing Channel Bottlenecks**\n\nI\u0027m now zeroing in on a potential flaw in the node\u0027s peer handling. It appears `ready_tx` is spammed every 200ms with *all* peers by `spawn_peer_feeder`, even if they are already working. This raises serious concurrency concerns because `PeerWorkScheduler` might be pulling the same peer ID from the channel, leading to duplicated work. The harness\u0027s bounded `ready_rx` offers a stark contrast, which may reveal a key performance bottleneck.\n\n\n",
        "thought": true
      }, {
        "text": "**Assessing \"In-Flight\" Logic**\n\nI\u0027m now zeroing in on a critical comparison of the \"in-flight\" request management. Specifically, I see how each peer handles requests. While the node uses a feeder to rapidly queue peers, the harness only re-queues them when their work is complete. The network layer, via `PeerRequestSender`, handles the pipeline requests. I\u0027m focusing on whether a flooded peer could lead to dropped requests.\n\n\n",
        "thought": true
      }, {
        "text": "**Evaluating Network Congestion**\n\nI\u0027m now diving into the network-level details, especially peer management. I\u0027ve noted the node\u0027s `PeerRequestSender`, a handle to an mpsc channel, and suspect excessive parallel requests to the same peer could be problematic. I see a `peer_feeder` that aggressively re-queues peers, potentially leading to channel congestion if peers can\u0027t keep up. The question is, does this over-eager queuing cause bottlenecks? I am seeing how the network layer is configured.\n\n\n",
        "thought": true
      }, {
        "text": "**Differentiating Peer Management**\n\nI\u0027m now comparing the \"node\" and \"harness\" peer management strategies. I see the node uses a `PeerPool` (RwLock\u003cVec\u003e), while the harness uses loose handles, passed through channels. The node\u0027s `peer_feeder` aggressively spams `ready_rx`, especially when the `PeerPool` is small, potentially creating contention. I need to determine the consequences of this `PeerPool` design in the context of network events.\n\n\n",
        "thought": true
      }, {
        "text": "**Investigating Wait/Backoff Logic**\n\nI\u0027m now zeroing in on a significant difference in how the \"node\" and \"harness\" handle periods of inactivity. The node\u0027s `run_benchmark_probe` function employs a 50ms sleep and re-queuing loop when the scheduler is idle or work can\u0027t be found for the given peer. The harness, conversely, simply drops the peer from the `ready_rx` loop if no work is available at that time, and relies on `next_batch_for_peer` to re-integrate the peer. I\u0027m focusing on the effect of the node\u0027s busy-loop on overall performance and resource utilization.\n\n\n",
        "thought": true
      }, {
        "text": "**Refining Peer Re-Integration**\n\nI\u0027m now focusing on peer re-integration in both systems. I\u0027ve realized the harness *does* drop peers from its main loop if there\u0027s no work, a potential inefficiency assuming the queue isn\u0027t always saturated, which is the assumption. The node, conversely, actively tries to keep peers alive, even when idle, which could cause overhead if its scheduler is constantly re-queuing empty tasks, which I am now confirming. My latest hypothesis is the node\u0027s P2P request implementation is the bottleneck, now taking a close look at `request_receipts_legacy` call.\n\n\n",
        "thought": true
      }, {
        "text": "**Examining Request Splitting**\n\nI\u0027ve been analyzing the receipt retrieval mechanisms. The node\u0027s `request_receipts_chunked` function, with its logic for handling partial results, now has my attention. I\u0027m comparing it against the harness\u0027s more straightforward approach. While the node does some receipt mapping and re-assembly, I\u0027m not convinced it would significantly slow things down. My focus now is on what the node does in its implementation of the P2P connection, and it is likely where the time is being spent.\n\n\n\n",
        "thought": true
      }, {
        "text": "**Comparing Pipeline Efficiency**\n\nI\u0027m now comparing the \"node\u0027s\" multi-stage pipeline with the \"harness\u0027s\" inline processing. The node\u0027s fetch-process-sink design, using multiple channels, is under scrutiny. I see a potential bottleneck in the multi-stage pipeline, and now I have more specific hypothesis on that area. I\u0027m focusing specifically on the impact of this channel-based design, and if the single-stage design is a factor.\n\n\n",
        "thought": true
      }, {
        "text": "**Identifying Data Movement Costs**\n\nI\u0027m now focusing on the performance implications of data movement through channels in the node. Specifically, the transfer of large `Vec\u003cReceipt\u003e` instances via `fetched_blocks_tx` is a key concern. In comparison to the harness, where the data is moved directly into a closure, the node\u0027s multi-channel approach might incur significant overhead due to memory copying. I am also investigating whether the channels are a cause of contention.\n\n\n",
        "thought": true
      }, {
        "text": "**Isolating Node Concurrency**\n\nThe node\u0027s excessive parallel requests to the same peer, due to its `peer_feeder`, are becoming clearer. The `PeerWorkScheduler` lacks \"peer busy\" tracking. Consequently, multiple concurrent `fetch_probe_batch` tasks might run for the same peer, which I see as the likely source of performance degradation. I\u0027m considering fixing this by modifying the `peer_feeder` loop.\n\n\n",
        "thought": true
      }, {
        "text": "**Fixing Concurrency Issues**\n\nI\u0027m now zeroing in on a pair of potential fixes, which includes removing the redundant peer feeder, which floods the ready channel. Next, I\u0027m going to optimize the pipeline to avoid sending the full fetched blocks to the processor thread. Finally, both node and harness use BinaryHeap, and Mutexes.\n\n\n",
        "thought": true
      }, {
        "text": "**Validating Queue Growth**\n\nI\u0027m confirming the \"infinite growth\" of queue items and concurrent overlapping requests to the same peer, as revealed by the code snippets. The `spawn_peer_feeder` aggressively pushes peers onto the `ready_tx` channel every 200ms, while `run_benchmark_probe` re-queues them. This 1-to-1 mapping explains the performance bottleneck. Now to focus on providing code fixes.\n\n\n",
        "thought": true
      }, {
        "text": "**Addressing Peer Flooding**\n\nI\u0027m now zeroing in on actionable code changes. The `peer_feeder` is the primary culprit, causing excessive parallel requests and queue growth, and needs adjustment within `sync/historical/mod.rs`. I\u0027m also planning to evaluate if there is any benefit to reducing channel serialization. The differences in locking strategy, particularly how the node handles batch assignment versus the harness, requires closer consideration.\n\n\n",
        "thought": true
      }]
    }, {
      "text": "Based on a detailed analysis of both the Harness (`repomix.harness.xml`) and the Node (`repomix.node.xml`), I have identified the primary bottleneck causing the performance gap (1200 blk/s vs 400 blk/s).\n\nThe architecture of the Node is significantly better (modular, clean separation of concerns), but there is a specific logic flaw in how work is scheduled that is causing **request congestion per peer**.\n\n### 1. The Bottleneck: Peer Overloading (The \"Smoking Gun\")\n\n**In the Harness:**\nA peer is treated as a single worker.\n1. A peer enters the `ready_rx` loop.\n2. A task is spawned for that peer.\n3. The peer is **removed** from the pool of available workers while the task is running.\n4. The peer is put back into `ready_tx` *only* after the task finishes.\n*Result:* **1 Batch Request per Peer at a time.**\n\n**In the Node (`sync/historical/mod.rs`):**\n1. The `spawn_peer_feeder` function runs every 200ms and pushes *every connected peer* into `ready_tx`.\n2. The `run_benchmark_probe` loop pulls a peer, assigns a batch, and spawns a fetch task.\n3. When the fetch task finishes, it *also* puts the peer back into `ready_tx`.\n4. **The Flaw:** Because the feeder keeps adding the same peers every 200ms, and the worker loop doesn\u0027t check if a peer is already busy, you end up spawning **multiple concurrent fetch tasks for the same peer**.\n\n**Why this kills performance:**\nInstead of 20 peers processing 1 request each, you likely have 20 peers trying to process 5–10 requests simultaneously. This causes:\n*   TCP Head-of-Line blocking.\n*   The remote peer throttling or dropping requests.\n*   High latency per request, which confuses the stats and reduces throughput.\n\n### 2. Architecture Comparison\n\n| Feature | Harness (Faster) | Node (Slower) | Analysis |\n| :--- | :--- | :--- | :--- |\n| **Peer Lifecycle** | **Sequential:** Peer works -\u003e finishes -\u003e queue. | **Flooded:** Peer works -\u003e queue; Feeder -\u003e queue (repeatedly). | **Critical Fix Needed.** |\n| **Pipeline** | **Inline:** Fetch -\u003e Verify -\u003e Stat -\u003e Drop. | **Staged:** Fetch -\u003e Channel -\u003e Process -\u003e Channel -\u003e Sink. | Channels add overhead (allocation/moves), but mostly negligible at 400 blk/s. |\n| **P2P Client** | **One-shot:** Creates new oneshot per request. | **Cloneable:** `NetworkPeer` is cloned, but uses same underlying channel. | Both use `reth-eth-wire` similarly. Safe, but flooding it causes latency. |\n| **Scheduling** | **Drop-if-empty:** If no work, peer is dropped (mostly). | **Busy-wait:** If no work, sleep 50ms and re-queue. | Node\u0027s approach keeps peers alive better but burns cycles if queue is empty. |\n\n---\n\n### 3. The Fixes\n\nHere are the specific changes to make the Node match (or beat) the Harness speed.\n\n#### Fix #1: Stop the `peer_feeder` from spamming (Critical)\n\nIn `sync/historical/mod.rs`, the `spawn_peer_feeder` function should only seed peers that are *new*, not constantly re-add existing ones. Since the fetch loop re-queues the peer upon completion, we don\u0027t need a timer loop pushing them back in.\n\n**Modify `sync/historical/mod.rs`:**\n\n```rust\n// In sync/historical/mod.rs\n\nfn spawn_peer_feeder(\n    pool: Arc\u003cPeerPool\u003e,\n    ready_tx: mpsc::UnboundedSender\u003ccrate::p2p::NetworkPeer\u003e,\n    mut shutdown_rx: watch::Receiver\u003cbool\u003e,\n) -\u003e tokio::task::JoinHandle\u003c()\u003e {\n    tokio::spawn(async move {\n        // Track which peers we have ever seen to avoid re-seeding them\n        // if they are already in the work cycle.\n        let mut seeded_peers: HashSet\u003cPeerId\u003e \u003d HashSet::new();\n\n        // Initial seed\n        for peer in pool.snapshot() {\n            if seeded_peers.insert(peer.peer_id) {\n                let _ \u003d ready_tx.send(peer);\n            }\n        }\n\n        // Only check for NEW peers periodically, don\u0027t re-send existing ones\n        let mut ticker \u003d tokio::time::interval(Duration::from_millis(1000)); \n        loop {\n            tokio::select! {\n                _ \u003d ticker.tick() \u003d\u003e {\n                    for peer in pool.snapshot() {\n                        // Only send if we haven\u0027t seen this peer_id before\n                        if seeded_peers.insert(peer.peer_id) {\n                            let _ \u003d ready_tx.send(peer);\n                        }\n                    }\n                }\n                _ \u003d shutdown_rx.changed() \u003d\u003e {\n                    if *shutdown_rx.borrow() {\n                        break;\n                    }\n                }\n            }\n        }\n    })\n}\n```\n\n#### Fix #2: Prevent Duplicate Scheduling\n\nEven with the feeder fixed, we want to ensure we don\u0027t process a peer that is already working (e.g., if a race condition occurs).\n\n**Modify `sync/historical/scheduler.rs`:**\n\nAdd a set to track busy peers.\n\n```rust\n// In PeerWorkScheduler struct\npub struct PeerWorkScheduler {\n    // ... existing fields ...\n    active_peers: Mutex\u003cHashSet\u003cPeerId\u003e\u003e, // Add this\n}\n\n// In next_batch_for_peer\npub async fn next_batch_for_peer(\u0026self, peer_id: PeerId, peer_head: u64) -\u003e Vec\u003cu64\u003e {\n    let mut active \u003d self.active_peers.lock().await;\n    if active.contains(\u0026peer_id) {\n        return Vec::new(); // Peer is already working, don\u0027t give it more\n    }\n    \n    // ... existing ban check ...\n    \n    // ... Logic to pick batch ...\n    \n    if !batch.is_empty() {\n        active.insert(peer_id); // Mark busy\n    }\n    batch\n}\n\n// Add a method to release the peer\npub async fn release_peer(\u0026self, peer_id: PeerId) {\n    let mut active \u003d self.active_peers.lock().await;\n    active.remove(\u0026peer_id);\n}\n```\n\n**Then update `run_benchmark_probe` in `sync/historical/mod.rs` to call release:**\n\n```rust\n// inside the fetch_tasks.spawn async block:\nfetch_tasks.spawn(async move {\n    // ... perform fetch ...\n    \n    // AFTER work is done (success or fail), before re-queueing:\n    scheduler.release_peer(peer.peer_id).await;\n    \n    let _ \u003d ready_tx.send(peer);\n});\n```\n\n#### Fix #3: Simplify Data Movement (Optimization)\n\nThe Node passes full `FetchedBlock` structs (containing heavy Receipts) through a channel to a processor, then to a sink. In Benchmark mode, you don\u0027t need to move the heavy data.\n\n**Modify `fetch_probe_batch` in `sync/historical/fetch.rs`:**\n\nInstead of returning `FetchedBlock` which holds `Vec\u003cReceipt\u003e`, calculate the count immediately and drop the data, returning a lighter struct.\n\nHowever, if you want to keep the architecture identical to Ingest (which needs the data), simply ensure the channel buffer isn\u0027t too huge. The current `mpsc::channel(2048)` is quite large. If `FetchedBlock` is large (lots of receipts), 2048 of them might cause memory pressure, triggering GC/allocator overhead. reducing this to `100` might actually help cache locality, though it\u0027s likely a minor factor compared to Fix #1.\n\n### Summary\n\nThe Node is slower because it is **accidentally DDoS-ing its own peers** due to the `peer_feeder` logic.\n\n1.  Apply **Fix #1** (Modify `spawn_peer_feeder` to only seed new peers).\n2.  (Optional but recommended) Apply **Fix #2** (Track active peers in Scheduler) to strictly enforce 1-request-per-peer.\n\nThis should bring the Node\u0027s performance in line with the Harness.",
      "role": "model",
      "finishReason": "STOP",
      "tokenCount": 1932,
      "parts": [{
        "text": "Based on a detailed analysis of both"
      }, {
        "text": " the Harness (`repomix.harness.xml`) and the Node (`repomix.node.xml`),"
      }, {
        "text": " I have identified the primary bottleneck causing the performance gap (1200 blk/s vs 400 bl"
      }, {
        "text": "k/s).\n\nThe architecture of the Node is significantly better (modular, clean separation of concerns), but there is a specific"
      }, {
        "text": " logic flaw in how work is scheduled that is causing **request congestion per peer**.\n\n### 1. The Bottleneck: Peer Over"
      }, {
        "text": "loading (The \"Smoking Gun\")\n\n**In the Harness:**\nA peer is treated as a single worker.\n1. A"
      }, {
        "text": " peer enters the `ready_rx` loop.\n2. A task is spawned for that peer.\n3. The peer"
      }, {
        "text": " is **removed** from the pool of available workers while the task is running.\n4. The peer is put back into `ready"
      }, {
        "text": "_tx` *only* after the task finishes.\n*Result:* **1 Batch Request per Peer at a time.**\n\n"
      }, {
        "text": "**In the Node (`sync/historical/mod.rs`):**\n1. The `spawn_peer_fe"
      }, {
        "text": "eder` function runs every 200ms and pushes *every connected peer* into `ready_tx`.\n2. The"
      }, {
        "text": " `run_benchmark_probe` loop pulls a peer, assigns a batch, and spawns a fetch task.\n3"
      }, {
        "text": ". When the fetch task finishes, it *also* puts the peer back into `ready_tx`.\n4. **"
      }, {
        "text": "The Flaw:** Because the feeder keeps adding the same peers every 200ms, and the worker loop doesn"
      }, {
        "text": "\u0027t check if a peer is already busy, you end up spawning **multiple concurrent fetch tasks for the same peer**.\n\n**"
      }, {
        "text": "Why this kills performance:**\nInstead of 20 peers processing 1 request each, you likely have 20"
      }, {
        "text": " peers trying to process 5–10 requests simultaneously. This causes:\n*   TCP Head-of-Line"
      }, {
        "text": " blocking.\n*   The remote peer throttling or dropping requests.\n*   High latency per request, which confuses the stats and"
      }, {
        "text": " reduces throughput.\n\n### 2. Architecture Comparison\n\n| Feature | Harness (Faster) | Node (Slower)"
      }, {
        "text": " | Analysis |\n| :--- | :--- | :--- | :--- |\n| **Peer Lifecycle** | **Sequential"
      }, {
        "text": ":** Peer works -\u003e finishes -\u003e queue. | **Flooded:** Peer works -\u003e queue; Feeder -\u003e queue (repeated"
      }, {
        "text": "ly). | **Critical Fix Needed.** |\n| **Pipeline** | **Inline:** Fetch -\u003e Verify -\u003e Stat -\u003e Drop"
      }, {
        "text": ". | **Staged:** Fetch -\u003e Channel -\u003e Process -\u003e Channel -\u003e Sink. | Channels add overhead (allocation/moves"
      }, {
        "text": "), but mostly negligible at 400 blk/s. |\n| **P2P Client** | **One"
      }, {
        "text": "-shot:** Creates new oneshot per request. | **Cloneable:** `NetworkPeer` is cloned, but uses"
      }, {
        "text": " same underlying channel. | Both use `reth-eth-wire` similarly. Safe, but flooding it causes latency. |\n|"
      }, {
        "text": " **Scheduling** | **Drop-if-empty:** If no work, peer is dropped (mostly). | **Busy"
      }, {
        "text": "-wait:** If no work, sleep 50ms and re-queue. | Node\u0027s approach keeps peers alive"
      }, {
        "text": " better but burns cycles if queue is empty. |\n\n---\n\n### 3. The Fixes\n\nHere are the specific changes to"
      }, {
        "text": " make the Node match (or beat) the Harness speed.\n\n#### Fix #1: Stop the `peer_feeder"
      }, {
        "text": "` from spamming (Critical)\n\nIn `sync/historical/mod.rs`, the `spawn_peer_fe"
      }, {
        "text": "eder` function should only seed peers that are *new*, not constantly re-add existing ones. Since the fetch loop re"
      }, {
        "text": "-queues the peer upon completion, we don\u0027t need a timer loop pushing them back in.\n\n**Modify"
      }, {
        "text": " `sync/historical/mod.rs`:**\n\n```rust\n// In sync/historical/mod.rs\n\n"
      }, {
        "text": "fn spawn_peer_feeder(\n    pool: Arc\u003cPeerPool\u003e,\n    ready_tx: m"
      }, {
        "text": "psc::UnboundedSender\u003ccrate::p2p::NetworkPeer\u003e,\n    mut shutdown_rx: watch::"
      }, {
        "text": "Receiver\u003cbool\u003e,\n) -\u003e tokio::task::JoinHandle\u003c()\u003e {\n    tokio::spawn(async"
      }, {
        "text": " move {\n        // Track which peers we have ever seen to avoid re-seeding them\n        // if they are already"
      }, {
        "text": " in the work cycle.\n        let mut seeded_peers: HashSet\u003cPeerId\u003e \u003d HashSet::new();\n\n        // Initial"
      }, {
        "text": " seed\n        for peer in pool.snapshot() {\n            if seeded_peers.insert(peer.peer_"
      }, {
        "text": "id) {\n                let _ \u003d ready_tx.send(peer);\n            }\n        }\n\n        "
      }, {
        "text": "// Only check for NEW peers periodically, don\u0027t re-send existing ones\n        let mut ticker \u003d tokio::time::"
      }, {
        "text": "interval(Duration::from_millis(1000)); \n        loop {\n            tokio::select! {"
      }, {
        "text": "\n                _ \u003d ticker.tick() \u003d\u003e {\n                    for peer in pool.snapshot() {\n                        // Only send"
      }, {
        "text": " if we haven\u0027t seen this peer_id before\n                        if seeded_peers.insert(peer.peer_id"
      }, {
        "text": ") {\n                            let _ \u003d ready_tx.send(peer);\n                        }\n                    }\n                }"
      }, {
        "text": "\n                _ \u003d shutdown_rx.changed() \u003d\u003e {\n                    if *shutdown_rx.borrow() {\n"
      }, {
        "text": "                        break;\n                    }\n                }\n            }\n        }\n    })\n}\n```\n\n####"
      }, {
        "text": " Fix #2: Prevent Duplicate Scheduling\n\nEven with the feeder fixed, we want to ensure we don\u0027t process a peer that"
      }, {
        "text": " is already working (e.g., if a race condition occurs).\n\n**Modify `sync/historical/scheduler."
      }, {
        "text": "rs`:**\n\nAdd a set to track busy peers.\n\n```rust\n// In PeerWorkScheduler struct\npub struct Peer"
      }, {
        "text": "WorkScheduler {\n    // ... existing fields ...\n    active_peers: Mutex\u003cHashSet\u003cPeerId\u003e\u003e,"
      }, {
        "text": " // Add this\n}\n\n// In next_batch_for_peer\npub async fn next_batch_for"
      }, {
        "text": "_peer(\u0026self, peer_id: PeerId, peer_head: u64) -\u003e Vec\u003cu"
      }, {
        "text": "64\u003e {\n    let mut active \u003d self.active_peers.lock().await;\n    if active.contains(\u0026"
      }, {
        "text": "peer_id) {\n        return Vec::new(); // Peer is already working, don\u0027t give it more"
      }, {
        "text": "\n    }\n    \n    // ... existing ban check ...\n    \n    // ... Logic to pick batch ...\n    \n"
      }, {
        "text": "    if !batch.is_empty() {\n        active.insert(peer_id); // Mark busy\n    }\n"
      }, {
        "text": "    batch\n}\n\n// Add a method to release the peer\npub async fn release_peer(\u0026self, peer_"
      }, {
        "text": "id: PeerId) {\n    let mut active \u003d self.active_peers.lock().await;\n    "
      }, {
        "text": "active.remove(\u0026peer_id);\n}\n```\n\n**Then update `run_benchmark_probe` in `sync/"
      }, {
        "text": "historical/mod.rs` to call release:**\n\n```rust\n// inside the fetch_tasks.spawn async block"
      }, {
        "text": ":\nfetch_tasks.spawn(async move {\n    // ... perform fetch ...\n    \n    // AFTER"
      }, {
        "text": " work is done (success or fail), before re-queueing:\n    scheduler.release_peer(peer."
      }, {
        "text": "peer_id).await;\n    \n    let _ \u003d ready_tx.send(peer);\n});\n"
      }, {
        "text": "```\n\n#### Fix #3: Simplify Data Movement (Optimization)\n\nThe Node passes full `FetchedBlock` structs (containing heavy"
      }, {
        "text": " Receipts) through a channel to a processor, then to a sink. In Benchmark mode, you don\u0027t need to"
      }, {
        "text": " move the heavy data.\n\n**Modify `fetch_probe_batch` in `sync/historical/fetch.rs"
      }, {
        "text": "`:**\n\nInstead of returning `FetchedBlock` which holds `Vec\u003cReceipt\u003e`, calculate the count immediately and drop the data"
      }, {
        "text": ", returning a lighter struct.\n\nHowever, if you want to keep the architecture identical to Ingest (which needs the data), simply"
      }, {
        "text": " ensure the channel buffer isn\u0027t too huge. The current `mpsc::channel(2048)` is quite"
      }, {
        "text": " large. If `FetchedBlock` is large (lots of receipts), 2048 of them might cause memory pressure,"
      }, {
        "text": " triggering GC/allocator overhead. reducing this to `100` might actually help cache locality, though it\u0027s likely"
      }, {
        "text": " a minor factor compared to Fix #1.\n\n### Summary\n\nThe Node is slower because it is **accidentally DDoS"
      }, {
        "text": "-ing its own peers** due to the `peer_feeder` logic.\n\n1.  Apply **Fix #1"
      }, {
        "text": "** (Modify `spawn_peer_feeder` to only seed new peers).\n2.  (Optional but"
      }, {
        "text": " recommended) Apply **Fix #2** (Track active peers in Scheduler) to strictly enforce 1-request-per-peer"
      }, {
        "text": ".\n\nThis should bring the Node\u0027s performance in line with the Harness."
      }, {
        "text": "",
        "thoughtSignature": "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"
      }]
    }],
    "pendingInputs": [{
      "text": "",
      "role": "user"
    }]
  }
}